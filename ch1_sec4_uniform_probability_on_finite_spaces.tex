\section{Uniform Probability on Finite Spaces}\label{unif_prob_fint_spc}
If the sample space $S$ is finite, then one possible probability measure on $S$ is the \term{uniform} probability
measure, which assigns probability $1/|S|$ to each outcome. Here $|S|$ is the number of elements in the sample space
$S$. By additivity, it then follows that for any event $A$ we have
\begin{equation}
    \label{eq:141}
    P(A) = \frac{|A|}{|S|}\,.
\end{equation}
\begin{example}
    Suppose we roll a six-sided die. The possible outcome are $S=\{1,2,3,4,5,6\}$, so that $|S|=6$. If the die is
    fair, then we believe each outcome is equally likely. We thus set $P(\{i\})=1/6$ for each $i \in S$ so that
    $P(\{3\})=1/6$, $P(\{4\})=1/6$, etc. It follows from \autoref{eq:141} that, for example, $P(\{3,4\})=2/6=1/3$,
    $P(\{1,5,6\})=3/6=1/2$, etc. This is a good model of rolling a fair six-sided die once.
\end{example}
\begin{example}
    For a second example, suppose we flip a fair coin once. Then $S=\{\text{heads, tails}\}$, so that $|S|=2$, and
    $P(\{\text{heads}\})=P(\{\text{tails}\})=1/2$.
\end{example}
\begin{example}\label{example:143}
    Suppose now that we flip \emph{three different} fair coins. The outcome can be written as a sequence of three
    letters, with each letter being $H$ (for heads) of $T$ (for tails). Thus,
    $$
    S = \{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\}\,.
    $$
    Here $|S|=8$, and each of the events is equally likely. Hence, $P(\{HHH\})=1/8$, $P(\{HHH,TTT\})=2/8=1/4$, etc.
    Note also that, by additivity, we have, for example, that $P(\text{exactly two heads}) = P(\{HHT, HTH,
    THH\})=1/8+1/8+1/8=3/8$, etc.
\end{example}
\begin{example}
    For a final example, suppose we roll a fair six-sided die \emph{and} flip a fair coin. Then we can write
    $$
    S=\{1H,2H,3H,4H,5H,6H,1T,2T, 3T, 4T, 5T, 6T\}\,.
    $$
    Hence, $|S|=12$ in this case, and $\forall s \in S, P(s)=1/12$.
\end{example}

\subsection{Combinatorial Principles}
Because of \autoref{eq:141}, problems involving uniform distributions on finite sample spaces often come down to
being able to compute the sizes $|A|$ and $|S|$ of the sets involved. That is, we need to be good at \emph{counting}
the number of elements in various sets. The science of counting is called \term{combinatorics}, and some aspects of
it are very sophisticated. In the remainder of this section, we consider a few simple combinatorial rules and their
application in probability theory when the uniform distribution is appropriate.

\begin{example}[Counting Sequences: The Multiplication Principle]
    Suppose we flip three fair coins and roll two fair six-sided dice. What is the probability that all three coins
    come up heads and that both dice come up 6? Each coin has two possible outcomes (heads or tails), and each die
    has six  possible outcomes $\{1,2,3,4,5,6\}$. The total number of possible outcomes of the three coins and two
    dice is thus given by \emph{multiplying} three 2's and two 6's, i.e., $2\times2\times2\times6\times6=288$. This is
    sometimes referred as the \term{multiplication principle}. There are thus 288 possible outcomes of our experiment
    (e.g., $HHH66$, $HTH24$, $TTH15$, etc.). Of these outcomes, only one (namely, $HHH66$) counts as a success. Thus,
    the probability that all three coins come up heads and both dice come up 6 is equal to 1/288.

    Notice that we can obtain this result in an alternative way. The chance that any one of the coins comes up heads
    is 1/2, and the chance that any one die comes 6 is 1/6. Furthermore, these events are all \emph{independent} (see
    next section). Under independence, the probability that they \emph{all} occur is given by the product of their
    individual probabilities, namely,
    $$
    (1/2)\times(1/2)\times(1/2)\times(1/6)\times(1/6)=1/288\,.
    $$

    More generally, suppose we have $k$ finite sets $S_1,\dots,S_k$ and we want to count the number of sequences of
    length $k$ where the $i$th element comes from $S_i$, i.e., count the number of elements in
    $$
    S = \{(s_1,\dots,s_k) : s \in S_i\} = S_1 \times \dots \times S_k\,.
    $$
    The multiplication principle says that the number of such sequences is obtained by multiplying together the
    number of elements in each set $S_i$, i.e.,
    $$
    |S| = |S_1|\times\dots\times|S_k|\,.
    $$
\end{example}

\begin{example}
    Suppose we roll two fair six-sided dice. What is the probability that the sum of the numbers showing is equal to 10? By the above multiplication principle, the total number of possible outcomes is equal to $6\times6=36$. Of these outcomes, there are three that sum to 10, namely, (4,6), (5,5), (6,4). Thus, the probability that the sum is 10 is equal to 3/36 or 1/12.
\end{example}

\begin{example}[\term{Counting permutations}]
    Suppose four friends go to a restaurant, and each checks his or her coat. At the end of the meal, the four coats are \emph{randomly} returned to the four people. What is the probability that each of the four people gets his or her own coat? Here the total number of different ways the coats can be returned  is equal to $4\times3\times2\times1$, or $4!$ (i.e., four factorial). This is because the first coat can be returned to any of the four friends, the second coat to any of the three remaining friends, and so on. Only one of these assignments is correct. Hence, the probability that each if the four people gets his or her own coat is equal to $1/4!$, or 1/24.

    Here we are counting permutations, or sequences of elements from a set where no element appears more than once. We can use the multiplication principle to count permutations more generally. For example, suppose $|S|=n$ and we want to count the number of permutations of length $k \leqslant n$ obtained from $S$, i.e., we want to count the number of elements of the set
    $$
    \{(s_1,\dots,s_k):s\in S, s_i \neq s_j \text{ when } i \neq j\}\,.
    $$
    Then we have $n$ choices for the first element $s_1$, $n-1$ choices for the second element, and finally $n-(k-1)=n-k+1$ choices for the last element. So there are $n\times(n-1)\times\dots\times(n-k+1)$ permutations of length $k$ from a set of $n$ elements. This can also be written as $n! / (n-k)!$. Notice that when $k=n$, there are
    $$
    n!=n\times(n-1)\times\dots\times2\times1
    $$
    permutations of length $n$.
\end{example}

\begin{example}[Counting Subsets]
    Suppose 10 fair coins are flipped. What is the probability that exactly seven of them are heads? Here each possible sequence of 10 heads or tails (e.g., $HHHTTTHTTT$, $THTTTTHHHT$, etc.) is equally likely, and by the multiplication principle the total number of possible outcomes is equal to 2 multiplied by itself 10 times, or $2^{10}=1024$. But of these sequences, how many have exactly seven heads?

    To answer this, notice that we may specify such a sequence by giving the positions of the seven heads, which involves choosing a subset of size 7 from the set of possible indices $\{1,\dots,10\}$. There are $10!/3!=10\times9\times\dots\times5\times4$ different permutations of length 7 from $\{1,\dots,10\}$, and each such permutation specifies a sequence of seven heads and three tails. But we can permute the indices specifying where the heads go in $7!$ different ways without changing the sequence of heads and tails. So the total number of outcomes with exactly seven heads is equal to $10!/(3!\cdot7!)=120$. The probability that exactly seven of the 10 coins are heads is therefore equal to $120/1024$, or just under 12\%.

    In general, if we have a set $S$ of $n$ elements, then the number of different subsets of size $k$ that we can construct by choosing elements from $S$ is
    $$
    \binom n k = \frac{n!}{k!(n-k)!}\,,
    $$
    which is called the \term{binomial coefficient}. This follows by the same argument, namely, there are $n!/(n-k)!$ permutations of length $k$ obtained from the set; each such permutation, and $k!$ permutations obtained by permuting it, specify a unique subset of $S$.
\end{example}

It follows, for example, that the probability of obtaining exactly $k$ heads when flipping a total of $n$  fair coins is  given by
$$
\binom{n}{k}2^{-n} = \frac{n!}{k!(n-k)!}2^{-n}\,.
$$
This is because there are $\binom n k$ different patterns of $k$ heads and $n-k$ tails, and a total of $2^n$ different sequences of $n$  heads and tails.

More generally, if each coin has probability $\theta$ of being heads (and probability $1-\theta$ of being tails), where $0 \leqslant \theta \leqslant 1$, then the probability of obtaining exactly $k$ heads when flipping a total of $n$ such coins is given by
\begin{equation}
    \binom{n}{k}\cdot\theta^k\cdot(1-\theta)^{n-k} = \frac{n!}{k!(n-k)!}\cdot\theta^k\cdot(1-\theta)^{n-k}\,,
\end{equation}
because each of the $\binom{n}{k}$ different patterns of $k$ heads and $n-k$ tails has probability $\theta^k(1-\theta)^{n-k}$ of occurring (this follows from the discussion of independence in \autoref{independence_of_events}). If $\theta=1/2$, then this reduces to the previous formula.

\begin{example}[Counting Sequence of Subsets and Partitions]
    Suppose we have a set $S$ of $n$ elements and we want to count the number of elements of
    \[
    \{(S_1, S_2,\dots,S_l): \forall i,j : i\leqslant l,j\leqslant l, i\neq j \Rightarrow S_i \subset S, |S_i|=k_i, S_i \cap S_j = \emptyset\}\,,
    \]
    namely, we want to count the number of sequences of $l$ subsets of a set where no two subsets have any elements in common and the $i$th subset has $k_i$ elements. By the multiplication principle, this equals
    \begin{equation}
        \label{eq:143}
        \binom{n}{k_1}\times\binom{n-k_1}{k_2}\times\dots\times\binom{n-k_1-\dots-k_{l-1}}{k_l} =        \frac{n!}{k_1!\times\dots\times k_{l-1}!\times k!\times(n-k_1-\dots-k_l)!}
    \end{equation}
    because we can choose the elements of $S_1$ in $\binom{n}{k_1}$ ways, choose the elements of $S_2$ in $\binom{n-k_1}{k_2}$ ways, etc.

    When we have that $S=S_1 \cup S_2 \cup \dots \cup S_l$, in addition to the individual sets being mutually disjoint, then we are counting the number of \term{ordered partitions} of a set of $n$ elements with $k_1$ elements in the first set, $k_2$ elements in the second set, etc. In this case, \autoref{eq:143} equals
    \begin{equation}\label{eq:144}
        \binom{n}{k_1\:k_2\:\dots\:k_l} = \frac{n!}{k_1!\times k_2!\times\dots\times k_l!}\,,
    \end{equation}
    which is called the \term{multinomial coefficient}.
\end{example}

For example, how many different bridge hands are there? By this we mean how many different ways can a deck of 52 cards be divided up into four hands of 13 cards each, with the hands labeled North, East, South, and West, respectively. By  \autoref{eq:144}, this equals
$$
\binom{52}{13\:13\:13\:13} = \frac{52!}{13!\cdot13!\cdot13!\cdot13!} \approx 5.364474 \times 10^{28}\,,
$$
which is very large number.

\begin{summary}
    \item The uniform probability distribution on a finite sample space $S$ satisfies $P(A)=|A|/|S|$.
    \item Computing $P(A)$ in this case requires computing the \emph{sizes} of the sets $A$ and $S$. This may require combinatorial principles such as the multiplication principle, factorials, and binomial/multinomial coefficients.
\end{summary}

\begin{exercises}
    \item Suppose we roll eight fair six-sided dice.
        \begin{enumerate}
            \item What is the probability that all eight dice show a 6?
            \item What is the probability that all eight dice show the same number?
            \item What is the probability that the sum of the eight dice is equal to 9?
        \end{enumerate}
    \item Suppose we roll 10 fair six-sided dice. What is the probability that there are exactly two 2's showing?
    \item Suppose we flip 100 fair independent coins. What is the probability that at least three of them are heads? (Hint: You may wish to use \autoref{eq:131}.)
    \item Suppose we are dealt five cards from an ordinary 52-card deck. What is the probability that
        \begin{enumerate}
            \item we get all four aces, plus the king of spades?
            \item  all five cards are spades?
            \item we get no pairs (i.e., all five cards are different values)?
            \item we get a full house (i.e., three cards of a kind, plus a different  pair)?
        \end{enumerate}
    \item Suppose we deal four 13-card bridge hands from an ordinary 52-card deck. What is the probability that
        \begin{enumerate}
            \item all 13 spades end up in the same hand?
            \item all four aces end up in the same hand?
        \end{enumerate}
    \item Suppose we pick two cards at random from an ordinary 52-card deck. What is the probability that the sum of the values of the two cards (where we count jacks, queens, and kings as 10, and count aces as 1) is at least 4?
    \item Suppose we keep dealing cards from an ordinary 52-card deck until the first jack appears. What is the probability that at least 10 cards go \emph{before} the first jack?
    \item In a well-shuffled ordinary 53-card deck, what is the probability that the ace of spades and ace of clubs are adjacent to each other?
    \item Suppose we repeatedly roll two fair six-sided dice, considering the \emph{sum} of the two values showing each time. What is the probability that the first time the sum is exactly 7 is on the third roll ?
    \item Suppose we roll three fair six-sided dice. What is the probability that two of them show the same value, but the third one does not?
    \item Consider two urns, labeled urn \#1 and urn \#2. Suppose urn \#1 has 5 red and  7 blue balls. Suppose urn \#2 has 6 red and 12 blue balls. Suppose we pick three balls uniformly at random from each of the two urns. What is the probability that all six chosen balls are the same color?
    \item Suppose we roll a fair six-sided die and flip three fair coins. What is the probability that the total number of heads is equal to the number showing on the die?
    \item Suppose we flip two pennies, three nickels, and four dimes. What is the probability that the total value of all coins showing heads is equal to \$0.31?
\end{exercises}

\begin{problems}
    \item Show that a probability measure defined by \autoref{eq:141} is always additive in the sense of \autoref{eq:additive_rule}.
    \item Suppose we roll eight fair six-sided dice. What is the probability that the sum of the eight dice is equal to 9? What is the probability that the sum of the eight dice is equal to 10? What is the probability that the sum of the eight dice is equal to 11?
    \item Suppose we roll one fair six-sided die, and flip six coins. What is the probability that the number of heads is equal to the number showing on the die?
    \item Suppose we roll 10 fair six-sided dice. What is the probability that there are exactly two 2's showing \emph{and} exactly three 3's showing?
    \item Suppose we deal four 13-card bridge hands from an ordinary 52-card deck. What is the probability that the North and East hands each have exactly the same number of spades?
    \item Suppose we pick a card at random from an ordinary 52-card deck and also flip 10 fair coins. What is the probability that the number of heads equals the value of the card (where we count jacks, queens, and kings as 10, and count aces as 1) ?
\end{problems}

\begin{challeges}
    \item Suppose we roll two fair six-sided dice and flip 12 coins. What is the probability that number of heads is equal to the sum of the numbers showing on two dice?
    \item (\emph{The} \term{birthday problem}) Suppose there are $C$ people, each of whose birthdays (month and day only) are equally likely to fall on any of the 365 days of a normal (i.e., non-leap) year.
        \begin{enumerate}
            \item Suppose $C=2$. What is the probability that the two people have the same exact birthday?
            \item Suppose $C\geqslant 2$. What is the probability that all $C$ people have the same exact birthday?
            \item Suppose $C\geqslant 2$. What is the probability that \emph{some pair} of the $C$ people have the same exact birthday? (Hint: You may wish to use \autoref{eq:131}.)
            \item What is the smallest value of $C$ such that the probability in part (c) is more than 0.5? Do you find this result surprising?
        \end{enumerate}
\end{challeges}
