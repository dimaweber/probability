\chapter{Preface}\label{preface}

This book is an introductory text on probability and statistics, targeting students who have studied one year of calculus at the university level and are seeking an introduction to probability and statistics with mathematical content. Where possible, we provide mathematical details, and it is expected that students are seeking to gain some mastery over these, as well as to learn how to conduct data analyses. All the usual methodologies covered in a typical introductory course are introduced, as well as some of the theory that serves as their justification.

The text can be used with or without a statistical computer package. It is our opinion that students should see the importance of various computational techniques in applications, and the book attempts to do this. Accordingly, we feel that computational
aspects of the subject,such as Monte Carlo, should be covered, even if a statistical package is not used. Almost any statistical package is suitable. A \nameref{app:computations} appendix provides an introduction to the R language. This covers all aspects of the language needed to do the computations in the text. Furthermore, we have provided the R code for any of the more complicated computations. Students can use these examples as templates for problems that involve such computations, e.g., using Gibbs sampling. Also, we have provided, in a separate section of this appendix, Minitab code for those computations that are  slightly involved, e.g., Gibbs sampling. No programming experience is required of students to do the problems.

We have organized the exercises in the book into groups, as an aid to users. \textbf{Exercises} are suitable for all students and offer practice in applying the concepts discussed in a particular section.  \textbf{Problems} require greater understanding, and a student can expect to spend more thinking time on these. If a problem is marked (MV), then it will require some facility with multivariable calculus beyond the first calculus course, although these problems are not necessarily hard. \textbf{Challenges} are problems that most students will find difficult; these are only for students who have no trouble with the \textbf{Exercises} and the \textbf{Problems}. There are also \textbf{Computer Exercises} and \textbf{Computer Problems}. where it is expected that students will make use of a statistical package in deriving solutions.

We have included a number of \textbf{Discussion Topics} designed to promote critical thinking in students. Throughout the book, we try to point students beyond the mastery of technicalities to think of the subject in a larger frame of reference. It is important that students acquire a sound mathematical foundation in the basic techniques of probability and statistics, which we believe this book will help students accomplish. Ultimately, however, these subjects are applied in real-world contexts, so it is equally important that students understand how to go about their application and understand what issues arise. Often, there are no right answers to \textbf{Discussion Topics}; their purpose is to get a student thinking about the subject matter. If these were to be used torr evaluation, then they would be answered in essay format and graded on the maturity the student showed with respect to the issues  involved. \textbf{Discussion Topics} are probably most suitable for smaller classes, but these will also benefit students who simply read them over and contemplate their relevance.

Some sections of the book are labeled \textbf{Advanced}. This material is aimed at students who are more mathematically mature (for example, they are taking, or have taken, a second course in calculus). All the \textbf{Advanced} material can be skipped, with no loss of continuity, by an instructor who wishes to do so. In particular, the final chapter of the text is labeled \textbf{Advanced} and would only be taught in a high-level introductory course aimed at specialists. Also, many proofs appear in the final section of many chapters, labeled \textbf{Further Proofs (Advanced)}. An instructor can choose which (if any) of these proofs they wish to present to their students.

As such, we feel that the material in the text is presented in a flexible way that allows the instructor to find an appropriate level for the students they are teaching. A \nameref{app:mathback} appendix reviews some mathematical concepts, from a first course on calculus, on case students could use a refresher, as well as brief introductions to partial derivatives, double integrals, etc.

\autoref{chap:probability_models} introduces the probability model and provides motivation for the study of probability. The basic properties of a probability measure are developed.

\autoref{chap:rvar_and_dist} deals with discrete, continuous, joint distributions, and the effects of a change of variable. It also introduces the topic of simulating from a probability distribution. The multivariate change of variable is developed in an \nameref{—Åhap:rvar_and_dist_sec:adv} section.

\autoref{chap:expect} introduces expectation. The probability-generating function is discussed, as are the moments and the moment-generating function of a random variable. This chapter develops some of the major inequalities used in probability. A section on characteristic functions is included as an Advanced topic.

\autoref{chap:sampl_dist_n_lim} deals with sampling distributions and limits. Convergence in probability, convergence with probability 1, the weak and strong laws of large numbers, convergence in distribution, and the central limit theorem are all introduced, along with various applications such as Monte Carlo. The normal distribution theory, necessary  for  many statistical applications, is also dealt with here.

As mentioned, Chapters \ref{chap:probability_models} through \ref{chap:sampl_dist_n_lim} include material on Monte Carlo techniques. Simulation is a key aspect of the application of probability theory, and it is our view that its teaching should be integrated with the theory right from the start. This reveals the power of probability to solve real-world problems and helps convince students that it is far more than just an interesting mathematical theory. No practitioner divorces himself from the theory when using the computer for computations or vice versa. We believe this is a more modern way of teaching the subject. This material can be skipped, however, if an instructor believes otherwise or feels there is not enough time to cover it effectively.

\autoref{chap:stat_infr} is an introduction to statistical inference. For most part, this is concerned with laying the groundwork for the development of more formal methodology in later chapters. So practical issues --- such as proper data collection, presenting data via graphical techniques, and informal inference methods like descriptive statistics --- are discussed here.

\autoref{ch6} deals with many of the standard methods of inference for one-sample problems. The theoretical justification for these methods is developed primarily through the likelihood function, but the treatment is still fairly informal. Basic methods of inference, such as the standard error of an estimate, confidence intervals, and $P$-values, are introduced. There is also a section devoted to distribution-free (nonparametric) methods like the bootstrap.

\autoref{ch7} involves many of the same problems discussed in \autoref{ch6}, but now from a Bayesian perspective. The point of view adopted here is not that Bayesian methods are better or, for that mattes, worse than those of \autoref{ch6}. Rather, we take the view that Bayesian methods arise naturally when the statistician adds another ingredient -- the prior -- to the model. The appropriateness of this,  or the sampling model for the data, is resolved through the model-checking methods of \autoref{ch9}. It is not our intention to have students adopt a particular philosophy. Rather, the text introduces students to a broad spectrum of statistical thinking.

Subsequent chapters deal with both frequentist and Bayesian approaches to the various problems discussed. The Bayesian material is in clearly labelled sections and can be skipped with no loss of continuity, if so desired. It has become apparent in recent years, however, that Bayesian methodology is widely used in applications. As such, we feel that it is important for students to be exposed to this, as well as to the frequentist approaches, early in their statistical education.

\autoref{ch8} deals with the traditional optimality justifications offered  for some statistical inferences. In particular, some aspects af optimal unbiased estimation and the Neyman-Pearson theorem are discussed. There is also a brief introduction to decision theory. This chapter is more formal and mathematical than  \autoref{chap:stat_infr}, \autoref{ch6} and \autoref{ch7}, and it can be skipped, with no loss of continuity, if an instructor wants to emphasize methods and applications.

\autoref{ch9} is on model checking. We placed model checking in separate chapter to emphasize its importance in applications. In practice, model checking is the way statisticians justify the choices they make in selecting the ingredients of a statistical problem. While these choices are inherently subjective, the methods of this chapter provide checks to make sure that the choices made are sensible in light of the objective observed data.

\autoref{ch10} is concerned with the statistical analysis of relationships among variables. This includes material