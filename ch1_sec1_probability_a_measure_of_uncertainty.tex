\section{Probability: A Measure of Uncertainty}
Often in life we are confronted by our own ignorance. Whether we are pondering tonight's traffic jam, tomorrow's weather, next week's stock prices, an upcoming election, or where we left our hat, often we do not know an outcome with certainty. Instead, we are forced to guess, to estimate, to hedge our bets.

Probability is the science of uncertainty. It provides precise mathematical rules for understanding and analyzing our own ignorance. It does not tell us tomorrow's weather or next week's stock prices; rather, it gives us a framework for working with our limited knowledge and for making sensible decisions based on what we do and do not know.

To say there is a 40\% chance of rain tomorrow is not to know tomorrow's weather. Rather, it is to know what we do
not know about tomorrow's weather.

In this text, we will develop a more precise understanding of what it means to say there is a 40\% chance of rain
tomorrow. We will learn how to work with ideas of randomness, probability, expected value, prediction, estimation,
etc., in ways that are sensible and mathematically clear.

There are also other sources of randomness beside uncertainty. For example, computers often use \term{pseudorandom
numbers} to make games fun, simulations accurate, and searches efficient. Also, according
to the modern theory of quantum mechanics, the makeup of atomic matter is in some sense \emph{truly} random. All such
sources of randomness can be studied using the techniques of this text.

Another way of thinking about probability is in terms of \term{relative frequency}. For
example, to say a coin has a 50\% chance of coming up heads can be interpreted as saying that, if we flipped coin
many, many, many times, then approximately half of the time it would come up heads. This interpretation has some
limitations. In many cases (such as tomorrow's weather or next week's stock prices), it is impossible to repeat the
experiment many, many, many times. Furthermore, what precisely does ``approximately'' mean in this case? However,
despite these limitations, the relative frequency interpretation is a useful way to think of probabilities and to
develop intuition about them.

Uncertainty has been with us forever, of course, but the mathematical theory of probability originated in the
seventeenth century. In 1654, the Paris gambler Le Chevalier de M\'er\'e asked Blaise Pascal about certain
probabilities that arose in gambling (such as, if a game of chance is interrupted in the middle, what is the
probability that each player would have won had the game continued?). Pascal was intrigued and corresponded with the
great mathematician and lawyer Pierre de Fermat about these questions. Pascal later wrote the book \emph{Trait\'e du
Triangle Arithmetique}, discussing binomial coefficients (Pascal's triangle) and the binomial probability
distribution.

At the beginning of the twentieth century, Russians such as Andrei Andreyevich Markov, Andrey Nikilayevich
Kolmogorov, and Pafnuty L. Chebychev (and American Norbert Wiener) developed a more formal mathematical theory of
probability. In the 1950s, Americans William Feller and Joe Doob wrote important books about the mathematics of
probability theory. They popularized the subject in the western world, both as an important area of pure mathematics
and as having important applications in physics, chemistry, and later in computer science, economics, and finance.

\subsection{Why Do We Need Probability Theory?}
\lipsum[1-10]
