\section{Probability Models}
A formal definition of probability begins with a \term{sample space}, often written  $S$. This
sample space is any set that lists all possible \term{outcomes} (or, \term{responses})
of some unknown experiment or situation. For example, perhaps
\begin{equation}
    S =  \{\text{rain, snow, clear}\} \notag
\end{equation}
when predicting tomorrow's weather. Or perhaps $S$ is the set of all positive real numbers, when predicting next
week's stock price. The point is, $S$ can be any set at all, even an infinite. We usually write $s$ for an element of
$S$, so that $s \in S$. Note that $S$ describes only those things that we are interested in; if we are studying
weather, then rain and snow are in $S$, but tomorrow's stock prices are not.

A probability model also requires a collection of \term{event}\emph{s}, which are subsets of $S$ to which
probabilities can be assigned. For the above weather example, the subsets \{rain\}, \{snow\}, \{rain,snow\}, \{rain,
clear\}, \{rain, snow, clear\}, and even the empty set $\emptyset = \{\,\}$ are all examples of subsets of $S$ that
could be events. Note that here the comma means ``or''; thus, \{rain, snow\} is the event that it will rain \emph{or}
snow. We will generally assume that \emph{all} subsets of $S$ are events. (In fact, in complicated situations there
are some technical restrictions on what subsets can or cannot be events, according to the mathematical subject of
measure theory. But we will not concern ourselves with such technicalities here.)

Finally, and most importantly, a probability model requires a \term{probability measure},
usually written $P$. This probability measure must assign, to each event $A$, a probability $P(A)$. We require the
following properties:
\begin{enumerate}
    \item $P(A)$ is always a nonnegative real number, between 0 and 1 inclusive.
    \item $P(\emptyset) = 0$, i.e., if $A$ is the empty set $\emptyset$, then $P(A)=0$.
    \item $P(S)=1$, i.e., if $A$ is the entire sample space $S$, then $P(A)=1$.
    \item $P$ is \emph{(countably)}~\term{additive}\index{countably additive}, meaning that if $A_1, A_2, \dots$ is
    finite or countable
    sequence of
    disjoint events, then
    \begin{equation}\label{eq:additive_rule}
        P(A_1 \cup A_2 \cup \ldots) = P(A_1) + P(A_2) + \ldots\,.
    \end{equation}
\end{enumerate}

The first of these properties says that we shall measure all probabilities on a scale from 0 to 1, where 0 means
impossible and 1 (or 100\%) means certain. The second property says the probability that \emph{nothing} happens is 0;
in other words, it is impossible that \emph{no} outcome will occur. The third property says the probability that
\emph{something} happens is 1; in other words, it is certain that \emph{some} outcome must occur.

The fourth property is the most subtle. It says that we can calculate probabilities of complicated events by adding
up  the probabilities of smaller events, provided those smaller events are \emph{disjoint} and together contain the
entire complicated event. Note that events  are \term{disjoint} if they contain no outcomes in
common. For example, \{rain\} and \{snow, clear\} are disjoint, whereas \{rain\} and \{rain, clear\} are not
disjoint. (We are assuming for simplicity that it cannot both rain \emph{and} snow tomorrow). Thus, we should have
$P(\{\text{rain}\}) + P(\{\text{snow, clear}\}) = P(\{\text{rain, snow, clear}\})$, but we do \emph{not} expect to
have $P(\{\text{rain}\}) + P(\{\text{rain, clear}\}) = P(\{\text{rain, rain, clear}\})$ (the latter being the same as
$P(\{\text{rain, clear}\})$).

We now formalize the definition of a probability model.
\begin{definition}[Probability model]
    A \term{probability model}    consists of a nonempty set called the sample space $S$; a collection of events that
    are subsets of $S$; and a probability measure $P$ assigning a probability between 0 and 1 to each event, with
    $P(\emptyset)=0$ and $P(S)=1$ and with $P$ additive as in \eqref{eq:additive_rule}.
\end{definition}

\begin{example}
    Consider again the weather example, with $S = \{\text{rain, snow, clear}\}$. Suppose that the probability of rain
    is 40\%, the probability of snow is 15\%, and the probability of a clear day is 45\%. We can express this as
    $P(\{\text{rain}\})=0.40$, $P(\{\text{snow}\})=0.15$, and $P(\{\text{clear}\})=0.45$.

    For this example, of course $P(\emptyset)=0$, i.e., it is impossible that \emph{nothing} will happen tomorrow.
    Also $P(\{\text{rain, snow, clear}\})=1$, because we are assuming that exactly \emph{one} of rain, snow, or clear
    must occur tomorrow. (To be more realistic, we might say that we are predicting the weather at exactly 11:00 A.M.
    tomorrow.) Now, what is the probability that it will rain \emph{or} snow tomorrow? Well, by additivity property,
    we see that
    $$
    P(\{\text{rain, snow}\}) = P(\{\text{rain}\}) + P(\{\text{snow}\}) = 0.40 + 0.15 = 0.55\,.
    $$
    We thus conclude that, as expected, there is a 55\% chance of rain \emph{or} snow tomorrow.
\end{example}

\begin{example}
    Suppose your candidate has a 60\% chance of winning an election in progress.Then $S=\{\text{win,lose}\}$, with
    $P(\text{win})=0.6$ and $P(\text{lose})=0.4$\,. Note that $P(\text{win})+P(\text{lose})=1$\,.
\end{example}

\begin{example}
    Suppose we flip a fair coin, which can come up either heads ($H$) or tails ($T$) with equal probability. Then
    $S=\{H, T\}$, with $P(H)=P(T)=0.5$\,. Of course, $P(H)+P(T)=1$\,.
\end{example}

\begin{example}
    Suppose we flip three fair coins in a row and keep track of the sequence of heads and tails that result. Then
    $$
    S = \{HHH, HHT, HTH, HTT, THH, THT, TTH, TTT\}.
    $$
    Furthermore, each of these eight outcomes is equally likely. Thus, $P(HHH)=1/8$, $P(TTT)=1/8$, etc. Also, the
    probability that the first coin is heads \emph{and} the second coin is tails, but the third coin can be anything,
    is equal to the sum of the probabilities of the event $HTH$ and $HTT$, i.e., $P(HTH)+P(HTT)=1/8+1/8=1/4$\,.
\end{example}

\begin{example}
    Suppose we flip three fair coins in a row but care only about the number of heads that result. Then
    $S=\{0,1,2,3\}$\,. However, the probabilities of these four outcomes are \emph{not} equally likely; we will see
    later that in fact $P(0)=P(3)=1/8$, while $P(1)=P(2)=3/8$\,.
\end{example}


We note that it is possible to define probability models on more complicated (e.g., uncountably infinite) sample
spaces as well.

\begin{example}
    Suppose that $S=[0,1]$ is the unit interval. We can define a probability measure $P$ on $S$ by saying that
    \begin{equation}
        P([a,b]) = b-a,\qquad \text{whenever $0 \leqslant a \leqslant b \leqslant 1$\,.}
    \end{equation}

    In words, for any\footnote{For the uniform distribution on $[0,1]$, it turns out that not all subsets of $[0,1]$
    can properly be regarded as \emph{events} for this model. However, this is merely a technical property, and any
    subset that we can explicitly write down will always be an event. See more advanced probability books,
    e.g.,~\cite[page 3]{B1}} subinterval $[a,b]$ of $[0,1]$, the probability of the interval is simply the
    \emph{length} of the interval. This example is called the \term{uniform distribution on $[0,1]$}. The uniform
    distribution is just the first of many distributions on uncountable state spaces. Many
    further examples will be given in \autoref{chap:rvar_and_dist}.
\end{example}

\subsection{Venn Diagrams and Subsets}
\term{Venn diagrams} provide a very useful graphical method for depicting the sample space $S$ and subsets of it. For
example, in \ref{venn_1} we have a Venn diagram showing the subset $A \subset S$ and the \term{complement}
$$
A^c = \{s:s\notin A\}
$$
of $A$. The rectangle denotes the entire sample space $S$. The circle (and its interior) denotes the subset~$A$; the
region outside the circle, but inside $S$ denotes $A^c$.
\begin{figure}[hb]
\missingfigure{Venn 1}
\caption{Venn diagram of the subsets $A$ and $A^c$ of the sample space $S$.}\label{venn_1}
\end{figure}

Two subsets $A \subset S$ and $B \subset S$ are depicted as two circles, as in \autoref{venn_2}. The
\term{intersection}
$$
A \cap B = \{s:s \in A \text{ and } s \in B\}
$$
of subsets $A$ and $B$ is the set of elements  common to both sets and is depicted by the region where the two
circles overlap. The set
$$
A \setminus B^c = \{s:s\in A \text{ and } s \notin B\}
$$
is called the \term{complement of $B$ in $A$} and is depicted as the region inside the $A$ circle, but not
inside the $B$ circle. This is the set of elements in   $A$ but not in $B$. Similarly, we have the complement of $A$
in $B$, namely, $A^c \cap B$. Observe that the sets $A\cap B$, $A \cap B^c$, and $A^c \cap B$ are mutually disjoint.

The \term{union}
$$
A \cup B = \{ s : s \in A \text{or} s \in B\}
$$
of sets $A$ and $B$ is the set of elements that are in either $A$ or $B$. In \autoref{venn_2}, it is depicted by the
region covered by both circles. Notice that $ A \cup B = \left(A \cap B^c\right) \cup (A \cap B) \cup (A^c \cap B)$\,.


There is one further region in \autoref{venn_2}. This is the complement of $A \cup B$, namely, the set of elements
that
are in neither $A$ nor $B$. So we immediately have
$$
    (A\cup B)^c = A^c \cap B^c\,.
$$
Similarly, we can show that
$$
    (A\cap B)^c = A^c \cup B^c
    \,,
$$
namely, the subset of elements that are not in both $A$ and $B$ is given by the set of elements not in $A$ or not in
$B$.
\begin{figure}[hb]
    \missingfigure{Venn 2}
    \caption{Venn diagram depicting the subsets $A$, $B$, $A\cap B$, $A\cap B^c$, $A^c \cap B$, $A^c \cap B^c$ and $A
    \cup B$.}\label{venn_2}
\end{figure}


Finally, we note that if $A$ and $B$ are disjoint subset, then it makes sense to depict these as drawn in
\autoref{venn_3}, i.e., as two nonoverlapping circles because they have no elements in common.
\begin{figure}[hb]
    \missingfigure{Venn 3}
    \caption{Venn diagram of disjoint subsets $A$ and $B$.}\label{venn_3}
\end{figure}

\begin{summary}
    \item A probability model consists of a sample space $S$ and a probability measure $P$ assigning probabilities to
    each event.
    \item Different sorts of sets can arise as sample spaces.
    \item Venn diagrams provide a convenient method for representing sets and the relationships among them.
\end{summary}

\begin{exercises}
    \item Suppose $S=\{1,2,3\}$, with $P(\{1\})=1/2$, $P(\{2\})=1/3$, and $P(\{3\})=1/6$.
        \begin{enumerate}
            \item What is $P(\{1,2\})$?
            \item What is $P(\{1,2,3\})$?
            \item List all events $A$ such that $P(A)=1/2$.
        \end{enumerate}
    \item Suppose $S=\{1,2,3,4,5,6,7,8\}$, with $P(\{s\})=1/8$ for $1 \leqslant s \leqslant 8$.
        \begin{enumerate}
            \item What is $P(\{1,2\})$?
            \item What is $P(\{1,2,3\})$?
            \item How many events $A$ are there such that $P(A) = 1/2$?
        \end{enumerate}
    \item Suppose $S=\{1,2,3\}$, with $P(\{1\})=1/2$ and $P(\{1,2\})=2/3$. What must $P(\{2\})$ be?
    \item Suppose $S=\{1,2,3\}$, and we try to define $P$ by $P(\{1,2,3\})=1$, $P(\{1,2\})=0.7$, $P(\{1,3\})=0.5$,
    $P(\{2,3\})=0.7$, $P({1})=0.2$, $P(\{2\})=0.5$, $P(\{3\})=0.3$. Is $P$ a valid probability measure? Why or why
    not?
    \item Consider the uniform distribution on $[0,1]$. Let $s \in [0,1]$ be any outcome. What is $P(\{s\})$? Do you
    find this result surprising?
    \item Label the subregions in the Venn diagram in \autoref{venn_4} using the sets $A$, $B$, and $C$ and their
    complements (just as we did in \autoref{venn_2}).
    \item On Venn diagram, depict the set of elements that are in subsets $A$ or $B$ but \emph{not} in both. Also
    write this as a subset involving unions and intersections of $A$, $B$, and their complements.
    \item Suppose $S=\{1,2,3\}$, and $P(\{1,2\})=1/3$, and $P(\{2,3\})=2/3$. Compute $P(\{1\})$, $P(\{2\})$, and
    $P(\{3\})$.
    \item Suppose $S=\{1,2,3,4\}$, and $P(\{1\})=1/12$, and $P(\{1,2\})=1/6$, and $P(\{1,2,3\})=1/3$. Compute
    $P(\{1\})$, $P(\{2\})$, $P(\{3\})$, and $P(\{4\})$.
    \item Suppose $S=\{1,2,3\}$, and $P(\{1\})=P(\{3\})=2P(\{2\})$. Compute $P(\{1\})$, $P(\{2\})$, and $P(\{3\})$.
    \item Suppose $S=\{1,2,3\}$, and $P(\{1\})=P(\{2\})+1/6$, and $P(\{3\})=2P(\{2\})$. Compute $P(\{1\})$,
    $P(\{2\})$, and $P(\{3\})$.
    \item Suppose $S=\{1,2,3,4\}$, and $P(\{1\})-1/8=P(\{2\})=3P(\{3\})=4P(\{4\})$. Compute $P(\{1\})$, $P(\{2\})$,
    $P(\{3\})$ and $P(\{4\})$.
\end{exercises}
\begin{figure}[h]
    \missingfigure{Venn 4}
    \caption{Venn diagram of subsets $A$, $B$ and $C$.}\label{venn_4}
\end{figure}

\begin{problems}
    \item Consider again the uniform distribution on $[0,1]$. Is it true that
    $$
    P([0,1]) = \sum_{s \in[0,1]}P(\{s\})\quad\text{?}
    $$
    How does this relate to the additivity property of probability measures?
    \item Suppose $S$ is a finite or countable set. Is it possible that $P(\{s\})=0$ for every single $s\in{}S$? Why
    or why not?
    \item Suppose $S$ is an uncountable set. Is it possible that $P(\{s\})=0$ for every single $s\in S$? Why or why
    not?
\end{problems}

\begin{discussion}
    \item Does the additivity property make sense intuitively? Why or why not?
    \item Is it important that we always have $P(S)=1$\,? How would probability theory change if this were not the
    case?
\end{discussion}